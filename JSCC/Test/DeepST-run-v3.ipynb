{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248b1169-3121-4a76-9d69-99000549d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: As far as the question of disposal costs is concerned , the fact is that very different systems are currently being applied here\n",
      "Output: As far as the question of disposal costs is concerned , the fact is as very different systems are being adopted here\n",
      "BLEU score: 0.7108332982740264\n",
      "\n",
      "Input: If you stop talking to them and don't keep them as a FB <unk> what's to worry about ?\n",
      "Output: If you stop talking to them and don't keep them as a FB someday what's to worry about ?\n",
      "BLEU score: 0.8492326635760689\n",
      "\n",
      "Input: I'm lucky I'm in a field where I can be curious for a living !\n",
      "Output: I'm lucky I'm in a field where I can be curious for a living !\n",
      "BLEU score: 1.0\n",
      "\n",
      "Input: My target demographic is specific but it is very <unk> women who like women\n",
      "Output: My target demographic is specific but it is very emphatically women who like women\n",
      "BLEU score: 0.7825422900366437\n",
      "\n",
      "Input: It can be hard to trust that people <unk> but many really do\n",
      "Output: It can be hard to trust that people brag but many really do\n",
      "BLEU score: 0.7611606003349892\n",
      "\n",
      "Input: We must not throw the baby out with the bath water\n",
      "Output: We must not throw the baby out with the bath water\n",
      "BLEU score: 1.0\n",
      "\n",
      "Input: This new crisis to hit European farmers has three major consequences\n",
      "Output: This new crisis to hit European farmers has three major consequences\n",
      "BLEU score: 1.0\n",
      "\n",
      "Input: Moldavia is linked with neighbouring Romania both culturally and politically\n",
      "Output: Woman is linked with neighbouring technical both odds and politically\n",
      "BLEU score: 0.32466791547509893\n",
      "\n",
      "Input: I <unk> <unk> I'm trying to forget I'm that old\n",
      "Output: I ado@@ I'm trying to trying forget I'm that old\n",
      "BLEU score: 0.392814650900513\n",
      "\n",
      "Input: We should welcome it and therefore welcome his report\n",
      "Output: We should welcome it and therefore welcome his report\n",
      "BLEU score: 1.0\n",
      "\n",
      "Input: <unk> thank you for the kind words <3\n",
      "Output: Aw thank you for the kind words <3\n",
      "BLEU score: 0.8408964152537145\n",
      "\n",
      "Input: Please don't use her as reference\n",
      "Output: Please don't use her as reference\n",
      "BLEU score: 1.0\n",
      "\n",
      "BLEU score mean: 0.8051789861542545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os  # use OS dependent functions like reading or writing files\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '10' # default is 8, Mac Book M1 Pro has 10 can support 10, which may slow down the computer \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "\n",
    "import numpy as np\n",
    "import collections # compute source_vocab\n",
    "from tqdm import tqdm \n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction \n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class Config:\n",
    "    E = 128\n",
    "    V = 128\n",
    "    sigma = 0.1   \n",
    "    num_steps = 40 \n",
    "    checkpoint_path = \"model_checkpoint.pth\"\n",
    "    corpus_train_vocab = \"corpus_train_vocab.txt\"\n",
    "    corpus_train_split = \"corpus_train_split.txt\"\n",
    "    input_file_path = \"input.txt\"\n",
    "    output_file_path = \"output.txt\"\n",
    "    batch_size = 32\n",
    "CONFIG = Config()\n",
    "\n",
    "\n",
    "\n",
    "class Vocab:  \n",
    "    # __init__ sorts the tokens by frequency in descending order, and assigns an index to each token\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): \n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = tokens\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],  \n",
    "                                   reverse=True)            # A list of tokens sorted by frequency\n",
    "        # Unknown tokens have an index of 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens  # List, idx corresponds to the position of token\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "        self.stoi = self.token_to_idx\n",
    "        self.itos = self.idx_to_token\n",
    "        self.tokens = self.idx_to_token[1:]\n",
    "\n",
    "    def __len__(self): # returns the length of the vocabulary\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens): # returns the index of a given token\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices): # returns the token corresponding to a given index\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    def to_indices(self, tokens): # returns the index corresponding to a given token\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.token_to_idx.get(token, self.unk) for token in tokens]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Unknown tokens have an index of 0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self): # returns the list of token frequencies that was sorted in descending order during initialization of the Vocab class.\n",
    "        return self._token_freqs\n",
    "\n",
    "## load here to allow dataset module to use the source_vocab file\n",
    "checkpoint = torch.load(CONFIG.checkpoint_path, map_location=torch.device('cpu'))\n",
    "source_vocab = checkpoint['source_vocab']\n",
    "train_corpus = open(CONFIG.corpus_train_split, 'r').readlines()  # the special \"\\n\" has not been processed\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):  # define Pytorch data set\n",
    "    def __init__(self, vocab=source_vocab, corpus=train_corpus):\n",
    "        self.vocab = vocab\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.corpus[index].strip().split() + ['<eos>']\n",
    "        return self.vocab[sentence], len(sentence)\n",
    "    \n",
    "\n",
    "def collate_fn(batch_data): \n",
    "    batch_data.sort(key=lambda xi: len(xi[0]), reverse=True)\n",
    "    data_length = [xi[1] for xi in batch_data]\n",
    "    data = [torch.tensor(xi[0]) for xi in batch_data]\n",
    "    padded_data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=1)\n",
    "    return padded_data, torch.tensor(data_length)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"position encoding\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "class MyEmbedding(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(MyEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), CONFIG.E, padding_idx=vocab['<pad>'])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.embedding(X)\n",
    "\n",
    "# with batch normalization\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.norm1 = nn.BatchNorm1d(CONFIG.V)\n",
    "        self.transformer_encoder1 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.norm2 = nn.BatchNorm1d(CONFIG.V)\n",
    "        self.transformer_encoder2 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.norm3 = nn.BatchNorm1d(CONFIG.V)\n",
    "        self.transformer_encoder3 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.linear1 = nn.Linear(CONFIG.V, 2 * CONFIG.V)\n",
    "        self.norm4 = nn.BatchNorm1d(2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, 16)\n",
    "        self.norm5 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X, valid_lens):\n",
    "        mask = (torch.arange((X.shape[1]), device=device).unsqueeze(0) >= valid_lens.unsqueeze(1)).to(device)\n",
    "        X2 = self.position_encoding(X)\n",
    "        X2_norm = self.norm1(X2.transpose(1, 2)).transpose(1, 2)\n",
    "        X3 = self.transformer_encoder1(X2_norm, src_key_padding_mask=mask)\n",
    "        X3_norm = self.norm2(X3.transpose(1, 2)).transpose(1, 2)\n",
    "        X4 = self.transformer_encoder2(X3_norm, src_key_padding_mask=mask)\n",
    "        X4_norm = self.norm3(X4.transpose(1, 2)).transpose(1, 2)\n",
    "        X5 = self.transformer_encoder3(X4_norm, src_key_padding_mask=mask)\n",
    "        X6 = self.linear1(X5)\n",
    "        X6_norm = self.norm4(X6.transpose(1, 2)).transpose(1, 2)\n",
    "        X7 = self.relu1(X6_norm)\n",
    "        X8 = self.linear2(X7)\n",
    "        X8_norm = self.norm5(X8.transpose(1, 2)).transpose(1, 2)\n",
    "        X9 = self.relu2(X8_norm)\n",
    "        return X9\n",
    "        \n",
    "def Channel(X):  # AWGN\n",
    "    return X + torch.normal(0, CONFIG.sigma, size=X.shape).to(device)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Decoder, self).__init__()\n",
    "        # reshape\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.linear1 = nn.Linear(16, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.transformer_decoder1 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder2 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder3 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.linear3 = nn.Linear(CONFIG.V, len(source_vocab))\n",
    "        \n",
    "    def forward(self, emb_decoder_input, channel_output, origin_len, tgt_mask=None, mode='train'):\n",
    "        memory_mask = (torch.arange((channel_output.shape[1]), dtype=torch.float32,\n",
    "                            device=device)[None, :] >= origin_len[:, None]).to(device)\n",
    "        channel_output = self.linear1(channel_output)\n",
    "        channel_output = self.relu1(channel_output)\n",
    "        channel_output = self.linear2(channel_output)\n",
    "        memory = self.relu2(channel_output)\n",
    "        emb_decoder_input = self.position_encoding(emb_decoder_input)\n",
    "        X6 = self.transformer_decoder1(emb_decoder_input, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X7 = self.transformer_decoder2(X6, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X8 = self.transformer_decoder3(X7, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X9 = self.linear3(X8)\n",
    "        return X9\n",
    "                \n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_dim=16, out_dim=64, latent_dim=8):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.mu = nn.Linear(out_dim, latent_dim)\n",
    "        self.logvar = nn.Linear(out_dim, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, in_dim)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, x.shape[-1]))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "class DeepST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepST, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.channel = Channel\n",
    "        self.decoder = Decoder()\n",
    "        self.vae = VAE(in_dim=16, out_dim=64) # change out_dim 16 to 64 for example\n",
    "    \n",
    "\n",
    "    def forward(self, emb_encoder_input, valid_lens, emb_decoder_input=None, embedding=None, phase=1):\n",
    "        encode_result = self.encoder(emb_encoder_input, valid_lens)\n",
    "\n",
    "        # VAE encoding and decoding\n",
    "        vae_encoded = self.vae.encode(encode_result)\n",
    "        vae_sampled = self.vae.reparameterize(*vae_encoded)\n",
    "        vae_decoded = self.vae.decode(vae_sampled)\n",
    "\n",
    "        channel_outputs = self.channel(encode_result)\n",
    "\n",
    "        \n",
    "        if phase == None:\n",
    "            mask = (torch.triu(torch.ones(emb_decoder_input.shape[1], emb_decoder_input.shape[1])) == 1).transpose(0, 1)\n",
    "            mask = (mask.masked_fill(mask == 0, True).masked_fill(mask == 1, False)).to(device)\n",
    "            return encode_result, self.channel(encode_result), \\\n",
    "                   self.decoder(torch.cat([embedding(torch.full([emb_decoder_input.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device)), \n",
    "                                        emb_decoder_input[:, :-1, :]], dim=1).to(device), \n",
    "                                channel_outputs,\n",
    "                                valid_lens, \n",
    "                                mask)\n",
    "        else:\n",
    "            return encode_result, self.channel(encode_result)\n",
    "\n",
    "\n",
    "class MI(nn.Module):\n",
    "    def __init__(self): #6 layers\n",
    "        super(MI, self).__init__()\n",
    "        self.linear1 = nn.Linear(16 * 2, 8 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(8 * CONFIG.V, 4 * CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.linear3 = nn.Linear(4 * CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.linear4 = nn.Linear(2 * CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        #self.dropout4 = nn.Dropout(p=0.5)\n",
    "        self.linear5 = nn.Linear(2 * CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        #self.dropout5 = nn.Dropout(p=0.5)\n",
    "        self.linear6 = nn.Linear(2 * CONFIG.V, 1)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "    def network(self, X, Y):\n",
    "        x = self.relu1(self.linear1(torch.cat([X, Y], dim=1)))\n",
    "        #x = self.dropout1(x)\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        #x = self.dropout2(x)\n",
    "        x = self.relu3(self.linear3(x))\n",
    "        #x = self.dropout3(x)\n",
    "        x = self.relu4(self.linear4(x))\n",
    "        #x = self.dropout4(x)\n",
    "        x = self.relu5(self.linear5(x))\n",
    "        #x = self.dropout5(x)\n",
    "        x = self.relu6(self.linear6(x))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, X, Y, valid_lens): \n",
    "        \n",
    "        mask = (torch.arange((X.shape[1]), dtype=torch.long,\n",
    "                            device=X.device)[None, :] >= valid_lens[:, None]).reshape(-1)\n",
    "        # Reshape X and Y first, then take them out\n",
    "        X = X.reshape(-1, 16)\n",
    "        Y = Y.reshape(-1, 16)\n",
    "        \n",
    "        X = X[mask == False]\n",
    "        Y = Y[mask == False]\n",
    "        \n",
    "        # sample\n",
    "        sample_size = X.shape[0]\n",
    "        idx = list(range(sample_size))\n",
    "        random.shuffle(idx)\n",
    "        idx = torch.tensor(idx).to(device)\n",
    "        X = X[idx]\n",
    "        Y = Y[idx]\n",
    "        idx_shuffle = list(range(sample_size))\n",
    "        random.shuffle(idx_shuffle)\n",
    "        idx_shuffle = torch.tensor(idx_shuffle).to(device)\n",
    "        shuffle_Y = Y[idx_shuffle]\n",
    "        \n",
    "        output_joint = self.network(X, Y)\n",
    "        output_marginal = self.network(X, shuffle_Y)\n",
    "        \n",
    "        return output_joint, output_marginal\n",
    "\n",
    "# Define the driving app\n",
    "def translate(input_file_path, output_file_path, checkpoint_path, batch_size=32, num_steps=40):\n",
    "    # Load the checkpoint\n",
    "    #checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    #source_vocab = checkpoint['source_vocab']\n",
    "    embedding_state_dict = checkpoint['embedding_state_dict']\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    \n",
    "    # Initialize the embedding and model\n",
    "    embedding = nn.Embedding.from_pretrained(torch.zeros((len(source_vocab), embedding_state_dict['embedding.weight'].shape[1])), freeze=False)\n",
    "    embedding_state_dict['weight'] = embedding_state_dict.pop('embedding.weight')\n",
    "    embedding.load_state_dict(embedding_state_dict)\n",
    "    embedding_state_dict['embedding.weight'] = embedding_state_dict.pop('weight')\n",
    "    model = DeepST().to(device)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Set up the data loader\n",
    "    input_corpus = open(CONFIG.input_file_path, 'r').readlines()\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=MyDataset(corpus=input_corpus), batch_size=CONFIG.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    num_steps = CONFIG.num_steps\n",
    "    bleus = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_corpus = open(CONFIG.input_file_path, 'r').readlines()\n",
    "        val_data_loader = torch.utils.data.DataLoader(dataset=MyDataset(corpus=val_corpus), batch_size=CONFIG.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "        for index, data in enumerate(tqdm(val_data_loader), 0):\n",
    "            inputs, valid_lens = data\n",
    "            inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "            emb_inputs = embedding(inputs)\n",
    "            _, channel_outputs = model(emb_inputs, valid_lens)\n",
    "            # decoder's first element is <bos>\n",
    "            outputs = torch.cat([torch.full([inputs.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device),\n",
    "                                 torch.full([inputs.shape[0], num_steps - 1], source_vocab['<pad>'], dtype=torch.long, device=device)],\n",
    "                                dim=1).to(device)\n",
    "            # continue_idxtest which sentence can continuously generate\n",
    "            continue_idx = torch.arange(inputs.shape[0], device=device)\n",
    "            num_step = 0\n",
    "            while not len(continue_idx) == 0 and num_step < num_steps - 1:\n",
    "                emb_outputs = embedding(outputs[continue_idx, :num_step + 1])\n",
    "                pred_words = model.decoder(emb_outputs, channel_outputs[continue_idx], valid_lens[continue_idx], mode='validate').argmax(dim=2)[:, -1:]\n",
    "                outputs[continue_idx, num_step + 1] = pred_words.squeeze(1)\n",
    "                continue_idx = continue_idx[(pred_words != source_vocab['<eos>']).squeeze(1)]\n",
    "                num_step += 1\n",
    "\n",
    "            # Postprocess the output sentence and print input/output pairs\n",
    "            for i in range(inputs.shape[0]):\n",
    "                input_sentence = source_vocab.to_tokens(list(inputs[i].cpu().numpy()))\n",
    "                input_sentence = [t for t in input_sentence if t not in ['<pad>', '<bos>', '<eos>']]\n",
    "                input_sentence = ' '.join(input_sentence)\n",
    "\n",
    "                output_sentence = source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy()))\n",
    "                output_sentence = [t for t in output_sentence if t not in ['<pad>', '<eos>']]\n",
    "                output_sentence = ' '.join(output_sentence)\n",
    "                print(f\"Input: {input_sentence}\")\n",
    "                print(f\"Output: {output_sentence}\")\n",
    "\n",
    "                # Compute the BLEU score\n",
    "                bleu = sentence_bleu([input_sentence.split()], output_sentence.split(), smoothing_function=SmoothingFunction().method1)\n",
    "                bleus.append(bleu)\n",
    "                print(f\"BLEU score: {bleu}\\n\")\n",
    "\n",
    "            if index == 2:\n",
    "                break\n",
    "\n",
    "        print(f'BLEU score mean: {sum(bleus) / len(bleus)}')\n",
    "\n",
    "        \n",
    "        \n",
    "# Call the function\n",
    "\n",
    "\n",
    "translate(CONFIG.input_file_path, CONFIG.output_file_path, CONFIG.checkpoint_path, CONFIG.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fbbc7-6cba-4f68-affa-6a36fd9d7a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
